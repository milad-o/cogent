# AgenticFlow Environment Configuration
# Copy to .env and fill in your values

# =============================================================================
# REQUIRED: Provider Selection
# =============================================================================

# LLM provider: gemini, openai, anthropic, groq, azure, ollama, mistral, github, cohere, cloudflare
LLM_PROVIDER=openai

# Embedding provider: openai, azure, ollama, github, cohere, cloudflare
EMBEDDING_PROVIDER=openai

# =============================================================================
# API Keys (set the one for your chosen LLM_PROVIDER)
# =============================================================================

OPENAI_API_KEY=
GEMINI_API_KEY=
ANTHROPIC_API_KEY=
GROQ_API_KEY=
COHERE_API_KEY=
MISTRAL_API_KEY=
GITHUB_TOKEN=
CLOUDFLARE_API_TOKEN=
CLOUDFLARE_ACCOUNT_ID=


# =============================================================================
# Azure OpenAI Configuration (if LLM_PROVIDER=azure or EMBEDDING_PROVIDER=azure)
# =============================================================================

# Required for Azure
AZURE_OPENAI_ENDPOINT=           # e.g., https://your-resource.openai.azure.com
AZURE_OPENAI_DEPLOYMENT=         # your chat deployment name
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=  # your embedding deployment name
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Authentication type: "api_key", "managed_identity", or "default"
AZURE_AUTH_TYPE=api_key

# For AZURE_AUTH_TYPE=api_key:
AZURE_OPENAI_API_KEY=

# For AZURE_AUTH_TYPE=managed_identity (Azure VMs, Functions, App Service, AKS):
# - System-assigned: leave AZURE_MANAGED_IDENTITY_CLIENT_ID empty
# - User-assigned: set to your managed identity's client ID
AZURE_MANAGED_IDENTITY_CLIENT_ID=

# For AZURE_AUTH_TYPE=default: Uses DefaultAzureCredential which tries:
# 1. Environment variables (AZURE_CLIENT_ID, AZURE_CLIENT_SECRET, AZURE_TENANT_ID)
# 2. Managed Identity (if running in Azure)
# 3. Azure CLI (az login)
# 4. VS Code Azure extension
# 5. Azure PowerShell

# =============================================================================
# Ollama Configuration (if LLM_PROVIDER=ollama or EMBEDDING_PROVIDER=ollama)
# =============================================================================

OLLAMA_HOST=http://localhost:11434
OLLAMA_CHAT_MODEL=qwen2.5:7b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# =============================================================================
# Model Overrides (optional - uses sensible defaults)
# =============================================================================

GEMINI_CHAT_MODEL=gemini-2.5-flash
OPENAI_CHAT_MODEL=gpt-4o
ANTHROPIC_CHAT_MODEL=claude-sonnet-4-20250514
GROQ_CHAT_MODEL=llama-3.3-70b-versatile
MISTRAL_CHAT_MODEL=mistral-small-latest
GITHUB_CHAT_MODEL=gpt-4o-mini
COHERE_CHAT_MODEL=command-r-plus
CLOUDFLARE_CHAT_MODEL=@cf/meta/llama-3.1-8b-instruct

OPENAI_EMBEDDING_MODEL=text-embedding-3-small
GITHUB_EMBEDDING_MODEL=text-embedding-3-large
COHERE_EMBEDDING_MODEL=embed-english-v3.0
CLOUDFLARE_EMBEDDING_MODEL=@cf/baai/bge-base-en-v1.5

# =============================================================================
# Other Settings
# =============================================================================

# Verbosity: minimal, verbose, debug, trace
VERBOSE_LEVEL=verbose

# =============================================================================
# Optional: Vector Store / Database
# =============================================================================

# Qdrant Cloud - https://cloud.qdrant.io
QDRANT_API_KEY=
QDRANT_URL=

# PostgreSQL (for pgvector)
DATABASE_URL=

# Together AI - https://api.together.xyz
TOGETHER_API_KEY=
