{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e252a9",
   "metadata": {},
   "source": [
    "# Math Problem Solving: Single vs Multi-Agent Comparison\n",
    "\n",
    "This notebook compares single-agent and multi-agent approaches for solving GSM8K-style math problems with verifiable outcomes.\n",
    "\n",
    "**Approaches:**\n",
    "- **Single Agent**: One agent with all math tools\n",
    "- **Multi-Agent**: Specialist agents (arithmetic, growth, equations) coordinated by an orchestrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6119a",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ed4a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from cogent import Agent, Observer, tool\n",
    "\n",
    "# Configure matplotlib for SVG output and better styling\n",
    "from matplotlib_inline import backend_inline\n",
    "backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7881d39b",
   "metadata": {},
   "source": [
    "## Tool Definitions\n",
    "\n",
    "Math operation tools with exact computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60deb9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tools defined\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> float:\n",
    "    \"\"\"Evaluate a mathematical expression safely.\n",
    "    \n",
    "    Args:\n",
    "        expression: Math expression (e.g., \"50 * 3\", \"200 + 150\", \"1000 - 105\")\n",
    "    \n",
    "    Returns:\n",
    "        The numerical result\n",
    "    \"\"\"\n",
    "    allowed_chars = set(\"0123456789+-*/()., \")\n",
    "    if not all(c in allowed_chars for c in expression):\n",
    "        raise ValueError(f\"Expression contains invalid characters: {expression}\")\n",
    "    \n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return float(result)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to evaluate '{expression}': {e}\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_percentage(value: float, percentage: float) -> float:\n",
    "    \"\"\"Calculate a percentage of a value.\n",
    "    \n",
    "    Args:\n",
    "        value: The base value\n",
    "        percentage: The percentage (e.g., 40 for 40%)\n",
    "    \n",
    "    Returns:\n",
    "        The calculated amount\n",
    "    \"\"\"\n",
    "    return (value * percentage) / 100\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_growth_rate(initial: float, final: float) -> float:\n",
    "    \"\"\"Calculate the growth rate between two values.\n",
    "    \n",
    "    Args:\n",
    "        initial: Starting value\n",
    "        final: Ending value\n",
    "    \n",
    "    Returns:\n",
    "        Growth rate as a percentage\n",
    "    \"\"\"\n",
    "    if initial == 0:\n",
    "        raise ValueError(\"Initial value cannot be zero\")\n",
    "    return ((final - initial) / initial) * 100\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_compound_growth(initial: float, rates: list[float]) -> float:\n",
    "    \"\"\"Calculate final value after applying multiple growth rates sequentially.\n",
    "    \n",
    "    Args:\n",
    "        initial: Starting value\n",
    "        rates: List of growth rates as percentages (e.g., [15, 23, -8, 31])\n",
    "    \n",
    "    Returns:\n",
    "        Final value after all growth applied\n",
    "    \"\"\"\n",
    "    value = initial\n",
    "    for rate in rates:\n",
    "        value = value * (1 + rate / 100)\n",
    "    return value\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate_average(values: list[float]) -> float:\n",
    "    \"\"\"Calculate the arithmetic mean of a list of values.\n",
    "    \n",
    "    Args:\n",
    "        values: List of numbers\n",
    "    \n",
    "    Returns:\n",
    "        The average value\n",
    "    \"\"\"\n",
    "    if not values:\n",
    "        raise ValueError(\"Cannot calculate average of empty list\")\n",
    "    return sum(values) / len(values)\n",
    "\n",
    "\n",
    "@tool\n",
    "def solve_linear_equation(a: float, b: float) -> float:\n",
    "    \"\"\"Solve linear equation: ax + b = 0\n",
    "    \n",
    "    Args:\n",
    "        a: Coefficient of x\n",
    "        b: Constant term\n",
    "    \n",
    "    Returns:\n",
    "        Solution for x\n",
    "    \"\"\"\n",
    "    if a == 0:\n",
    "        raise ValueError(\"Coefficient 'a' cannot be zero in linear equation\")\n",
    "    return -b / a\n",
    "\n",
    "\n",
    "print(\"✓ Tools defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc92d26",
   "metadata": {},
   "source": [
    "## Problem Definitions\n",
    "\n",
    "GSM8K-style math problems with exact answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc5fa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 3 problems defined:\n",
      "  1. Compound growth: Answer = 4,091,412.96\n",
      "  2. Multi-step percentages: Answer = 112.50\n",
      "  3. Revenue & expenses: Answer = 895.00\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class MathProblem:\n",
    "    \"\"\"A math problem with a verifiable answer.\"\"\"\n",
    "    question: str\n",
    "    ground_truth: float\n",
    "    description: str\n",
    "\n",
    "\n",
    "PROBLEMS = [\n",
    "    MathProblem(\n",
    "        question=\"\"\"A company's revenue was $2.4M at the start of the year.\n",
    "It grew 15% in Q1, 23% in Q2, fell 8% in Q3, then grew 31% in Q4.\n",
    "What was the final revenue? Also calculate the average quarterly growth rate.\"\"\",\n",
    "        ground_truth=4091412.96,\n",
    "        description=\"Compound growth\"\n",
    "    ),\n",
    "    \n",
    "    MathProblem(\n",
    "        question=\"\"\"A store had 150 apples. On Monday, they sold 40% of them.\n",
    "On Tuesday, they received a shipment that increased their stock by 60 apples.\n",
    "On Wednesday, they sold 25% of their current stock.\n",
    "How many apples remain?\"\"\",\n",
    "        ground_truth=112.5,\n",
    "        description=\"Multi-step percentages\"\n",
    "    ),\n",
    "    \n",
    "    MathProblem(\n",
    "        question=\"\"\"A carnival booth made $50 per day selling popcorn.\n",
    "It made three times as much selling cotton candy each day.\n",
    "Over 5 days, the booth earned revenue but had to pay $30 rent and $75 for ingredients.\n",
    "What was the profit after expenses?\"\"\",\n",
    "        ground_truth=895.0,\n",
    "        description=\"Revenue & expenses\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"✓ {len(PROBLEMS)} problems defined:\")\n",
    "for i, p in enumerate(PROBLEMS, 1):\n",
    "    print(f\"  {i}. {p.description}: Answer = {p.ground_truth:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2c0a85",
   "metadata": {},
   "source": [
    "## Structured Output Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8524f008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Output schema defined\n"
     ]
    }
   ],
   "source": [
    "class MathSolution(BaseModel):\n",
    "    \"\"\"Structured output for math problem solutions.\"\"\"\n",
    "    reasoning: str = Field(description=\"Step-by-step explanation of how you solved the problem\")\n",
    "    final_answer: float = Field(description=\"The final numerical answer to the problem\")\n",
    "\n",
    "\n",
    "print(\"✓ Output schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f5e88",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd3e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class EvaluationResult:\n",
    "    \"\"\"Results from solving a problem.\"\"\"\n",
    "    problem_description: str\n",
    "    ground_truth: float\n",
    "    agent_answer: float | None\n",
    "    reasoning: str\n",
    "    duration: float\n",
    "    tokens: int\n",
    "    tool_calls: int\n",
    "    correct: bool\n",
    "\n",
    "\n",
    "async def evaluate_approach(agent: Agent, problem: MathProblem) -> EvaluationResult:\n",
    "    \"\"\"Evaluate one problem with one agent.\"\"\"\n",
    "    start = time.time()\n",
    "    response = await agent.run(problem.question, output=MathSolution)\n",
    "    duration = time.time() - start\n",
    "    \n",
    "    # Get structured output - it's wrapped in StructuredResult\n",
    "    from cogent.agent.output import StructuredResult\n",
    "    if isinstance(response.content, StructuredResult):\n",
    "        solution = response.content.data\n",
    "    else:\n",
    "        solution = response.content\n",
    "    \n",
    "    answer = solution.final_answer if isinstance(solution, MathSolution) else None\n",
    "    reasoning = solution.reasoning if isinstance(solution, MathSolution) else \"No solution provided\"\n",
    "    \n",
    "    # Check correctness\n",
    "    correct = answer is not None and answer == problem.ground_truth\n",
    "    \n",
    "    # Count tool calls (including subagent tool calls)\n",
    "    tool_calls = len(response.tool_calls)\n",
    "    if response.subagent_responses:\n",
    "        for sub_resp in response.subagent_responses:\n",
    "            tool_calls += len(sub_resp.tool_calls)\n",
    "    \n",
    "    return EvaluationResult(\n",
    "        problem_description=problem.description,\n",
    "        ground_truth=problem.ground_truth,\n",
    "        agent_answer=answer,\n",
    "        reasoning=reasoning,\n",
    "        duration=duration,\n",
    "        tokens=response.metadata.tokens.total_tokens,\n",
    "        tool_calls=tool_calls,\n",
    "        correct=correct,\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"✓ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89d6fe",
   "metadata": {},
   "source": [
    "## Agent Setup\n",
    "\n",
    "### Single Agent (all tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "observer = Observer(level=\"progress\")\n",
    "\n",
    "single_agent = Agent(\n",
    "    name=\"MathSolver\",\n",
    "    model=\"gemini:gemini-2.5-pro\",\n",
    "    instructions=\"\"\"You are an expert mathematics problem solver.\n",
    "    \n",
    "Solve problems step-by-step using the available tools.\n",
    "Show your reasoning clearly, then provide the final numerical answer.\"\"\",\n",
    "    tools=[\n",
    "        calculator,\n",
    "        calculate_percentage,\n",
    "        calculate_growth_rate,\n",
    "        calculate_compound_growth,\n",
    "        calculate_average,\n",
    "        solve_linear_equation,\n",
    "    ],\n",
    "    observer=observer,\n",
    ")\n",
    "\n",
    "print(\"✓ Single agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a2d153",
   "metadata": {},
   "source": [
    "### Multi-Agent (specialists + orchestrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ff522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic specialist\n",
    "arithmetic_expert = Agent(\n",
    "    name=\"ArithmeticExpert\",\n",
    "    model=\"gemini:gemini-2.5-flash\",\n",
    "    instructions=\"\"\"You are an arithmetic specialist.\n",
    "    \n",
    "Use the calculator and percentage tools to perform calculations accurately.\n",
    "Show each step of your work clearly.\"\"\",\n",
    "    tools=[calculator, calculate_percentage],\n",
    ")\n",
    "\n",
    "# Growth/statistics specialist\n",
    "growth_expert = Agent(\n",
    "    name=\"GrowthExpert\",\n",
    "    model=\"gemini:gemini-2.5-flash\",\n",
    "    instructions=\"\"\"You are a growth and statistics specialist.\n",
    "    \n",
    "Use growth rate and compound growth tools to analyze changes over time.\n",
    "Calculate averages when needed.\"\"\",\n",
    "    tools=[calculate_growth_rate, calculate_compound_growth, calculate_average],\n",
    ")\n",
    "\n",
    "# Equation solver specialist\n",
    "equation_expert = Agent(\n",
    "    name=\"EquationExpert\",\n",
    "    model=\"gemini:gemini-2.5-flash\",\n",
    "    instructions=\"\"\"You are an equation solving specialist.\n",
    "    \n",
    "Solve linear equations using the provided tool.\n",
    "Explain the solution process.\"\"\",\n",
    "    tools=[solve_linear_equation],\n",
    ")\n",
    "\n",
    "# Orchestrator that delegates to specialists\n",
    "multi_agent_orchestrator = Agent(\n",
    "    name=\"MathOrchestrator\",\n",
    "    model=\"gemini:gemini-2.5-pro\",\n",
    "    instructions=\"\"\"You are a math problem orchestrator.\n",
    "    \n",
    "Break down complex problems and delegate to specialists:\n",
    "- ArithmeticExpert: Basic calculations, percentages\n",
    "- GrowthExpert: Growth rates, compound growth, averages\n",
    "- EquationExpert: Solving equations\n",
    "\n",
    "Synthesize their results into a final answer with clear reasoning.\"\"\",\n",
    "    subagents=[arithmetic_expert, growth_expert, equation_expert],\n",
    "    observer=observer,\n",
    ")\n",
    "\n",
    "print(\"✓ Multi-agent system created (3 specialists + orchestrator)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d42996f",
   "metadata": {},
   "source": [
    "## Run Evaluation\n",
    "\n",
    "Solve all problems with both approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_results = []\n",
    "multi_results = []\n",
    "\n",
    "for i, problem in enumerate(PROBLEMS, 1):\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"PROBLEM {i}: {problem.description}\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "    print(f\"Ground Truth: {problem.ground_truth:,.2f}\\n\")\n",
    "    \n",
    "    # Single agent\n",
    "    print(\"Single Agent...\")\n",
    "    result_single = await evaluate_approach(single_agent, problem)\n",
    "    single_results.append(result_single)\n",
    "    status = \"✓ CORRECT\" if result_single.correct else \"✗ WRONG\"\n",
    "    print(f\"  {status} | {result_single.duration:.1f}s | {result_single.tokens:,} tokens | {result_single.tool_calls} tools\")\n",
    "    \n",
    "    # Multi-agent\n",
    "    print(\"Multi-Agent...\")\n",
    "    result_multi = await evaluate_approach(multi_agent_orchestrator, problem)\n",
    "    multi_results.append(result_multi)\n",
    "    status = \"✓ CORRECT\" if result_multi.correct else \"✗ WRONG\"\n",
    "    print(f\"  {status} | {result_multi.duration:.1f}s | {result_multi.tokens:,} tokens | {result_multi.tool_calls} tools\")\n",
    "\n",
    "print(\"\\n✓ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2b4664",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "\n",
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "\n",
    "for i, (single, multi) in enumerate(zip(single_results, multi_results), 1):\n",
    "    comparison_data.append({\n",
    "        'Problem': f\"P{i}: {single.problem_description}\",\n",
    "        'Ground Truth': single.ground_truth,\n",
    "        'Single Answer': single.agent_answer,\n",
    "        'Single Correct': '✓' if single.correct else '✗',\n",
    "        'Single Time (s)': round(single.duration, 1),\n",
    "        'Single Tokens': single.tokens,\n",
    "        'Single Tools': single.tool_calls,\n",
    "        'Multi Answer': multi.agent_answer,\n",
    "        'Multi Correct': '✓' if multi.correct else '✗',\n",
    "        'Multi Time (s)': round(multi.duration, 1),\n",
    "        'Multi Tokens': multi.tokens,\n",
    "        'Multi Tools': multi.tool_calls,\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "display(df)\n",
    "\n",
    "# Calculate totals\n",
    "single_correct = sum(1 for r in single_results if r.correct)\n",
    "multi_correct = sum(1 for r in multi_results if r.correct)\n",
    "single_tokens = sum(r.tokens for r in single_results)\n",
    "multi_tokens = sum(r.tokens for r in multi_results)\n",
    "single_time = sum(r.duration for r in single_results)\n",
    "multi_time = sum(r.duration for r in multi_results)\n",
    "single_tools = sum(r.tool_calls for r in single_results)\n",
    "multi_tools = sum(r.tool_calls for r in multi_results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOTALS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Accuracy:     Single {single_correct}/{len(PROBLEMS)} | Multi {multi_correct}/{len(PROBLEMS)}\")\n",
    "print(f\"Total Tokens: Single {single_tokens:,} | Multi {multi_tokens:,} ({((multi_tokens/single_tokens - 1) * 100) if single_tokens > 0 else 0:+.1f}%)\")\n",
    "print(f\"Total Tools:  Single {single_tools} | Multi {multi_tools} ({multi_tools - single_tools:+d})\")\n",
    "print(f\"Total Time:   Single {single_time:.1f}s | Multi {multi_time:.1f}s ({((multi_time/single_time - 1) * 100) if single_time > 0 else 0:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0d13a3",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "### 1. Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "approaches = ['Single Agent', 'Multi-Agent']\n",
    "accuracies = [single_correct / len(PROBLEMS) * 100, multi_correct / len(PROBLEMS) * 100]\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "\n",
    "bars = ax.bar(approaches, accuracies, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{acc:.1f}%\\n({int(acc/100*len(PROBLEMS))}/{len(PROBLEMS)})',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Accuracy Comparison: Single vs Multi-Agent', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_ylim(0, 110)\n",
    "ax.axhline(y=100, color='green', linestyle='--', alpha=0.3, label='Perfect Score')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb64824",
   "metadata": {},
   "source": [
    "### 2. Resource Usage Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a686ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics = [\n",
    "    ('Tokens', [single_tokens, multi_tokens], 'Total Tokens Used'),\n",
    "    ('Tool Calls', [single_tools, multi_tools], 'Total Tool Calls'),\n",
    "    ('Time (s)', [single_time, multi_time], 'Total Time (seconds)'),\n",
    "]\n",
    "\n",
    "for ax, (metric, values, title) in zip(axes, metrics):\n",
    "    bars = ax.bar(approaches, values, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        if metric == 'Tokens':\n",
    "            label = f'{int(val):,}'\n",
    "        elif metric == 'Time (s)':\n",
    "            label = f'{val:.1f}s'\n",
    "        else:\n",
    "            label = f'{int(val)}'\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                label, ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9528715",
   "metadata": {},
   "source": [
    "### 3. Per-Problem Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68227827",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "problem_labels = [f\"P{i}\" for i in range(1, len(PROBLEMS) + 1)]\n",
    "x = range(len(PROBLEMS))\n",
    "width = 0.35\n",
    "\n",
    "# 1. Correctness per problem\n",
    "ax = axes[0]\n",
    "single_correct_vals = [1 if r.correct else 0 for r in single_results]\n",
    "multi_correct_vals = [1 if r.correct else 0 for r in multi_results]\n",
    "\n",
    "ax.bar([i - width/2 for i in x], single_correct_vals, width, label='Single', color=colors[0], alpha=0.7)\n",
    "ax.bar([i + width/2 for i in x], multi_correct_vals, width, label='Multi', color=colors[1], alpha=0.7)\n",
    "ax.set_ylabel('Correct (1) / Wrong (0)')\n",
    "ax.set_title('Correctness per Problem', fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(problem_labels)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Tokens per problem\n",
    "ax = axes[1]\n",
    "single_token_vals = [r.tokens for r in single_results]\n",
    "multi_token_vals = [r.tokens for r in multi_results]\n",
    "\n",
    "ax.bar([i - width/2 for i in x], single_token_vals, width, label='Single', color=colors[0], alpha=0.7)\n",
    "ax.bar([i + width/2 for i in x], multi_token_vals, width, label='Multi', color=colors[1], alpha=0.7)\n",
    "ax.set_ylabel('Tokens')\n",
    "ax.set_title('Token Usage per Problem', fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(problem_labels)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Tool calls per problem\n",
    "ax = axes[2]\n",
    "single_tool_vals = [r.tool_calls for r in single_results]\n",
    "multi_tool_vals = [r.tool_calls for r in multi_results]\n",
    "\n",
    "ax.bar([i - width/2 for i in x], single_tool_vals, width, label='Single', color=colors[0], alpha=0.7)\n",
    "ax.bar([i + width/2 for i in x], multi_tool_vals, width, label='Multi', color=colors[1], alpha=0.7)\n",
    "ax.set_ylabel('Tool Calls')\n",
    "ax.set_title('Tool Calls per Problem', fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(problem_labels)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Time per problem\n",
    "ax = axes[3]\n",
    "single_time_vals = [r.duration for r in single_results]\n",
    "multi_time_vals = [r.duration for r in multi_results]\n",
    "\n",
    "ax.bar([i - width/2 for i in x], single_time_vals, width, label='Single', color=colors[0], alpha=0.7)\n",
    "ax.bar([i + width/2 for i in x], multi_time_vals, width, label='Multi', color=colors[1], alpha=0.7)\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title('Execution Time per Problem', fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(problem_labels)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646694c",
   "metadata": {},
   "source": [
    "### 4. Efficiency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5698e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate efficiency metrics\n",
    "efficiency_data = {\n",
    "    'Approach': ['Single Agent', 'Multi-Agent'],\n",
    "    'Tokens per Problem': [single_tokens / len(PROBLEMS), multi_tokens / len(PROBLEMS)],\n",
    "    'Time per Problem (s)': [single_time / len(PROBLEMS), multi_time / len(PROBLEMS)],\n",
    "    'Tools per Problem': [single_tools / len(PROBLEMS), multi_tools / len(PROBLEMS)],\n",
    "}\n",
    "\n",
    "efficiency_df = pd.DataFrame(efficiency_data)\n",
    "efficiency_df['Tokens per Problem'] = efficiency_df['Tokens per Problem'].round(0).astype(int)\n",
    "efficiency_df['Time per Problem (s)'] = efficiency_df['Time per Problem (s)'].round(2)\n",
    "efficiency_df['Tools per Problem'] = efficiency_df['Tools per Problem'].round(1)\n",
    "\n",
    "print(\"Efficiency Metrics (Average per Problem):\")\n",
    "display(efficiency_df)\n",
    "\n",
    "# Visualize efficiency\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "normalized_data = efficiency_df.set_index('Approach').T\n",
    "normalized_data_scaled = normalized_data.div(normalized_data.max(axis=1), axis=0) * 100\n",
    "\n",
    "normalized_data_scaled.plot(kind='barh', ax=ax, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Relative Usage (% of maximum)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Relative Resource Efficiency (lower is better)', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend(title='Approach', loc='lower right')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b695e8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the per-call structured output feature in Cogent, comparing single-agent vs multi-agent approaches on math problems.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- Both approaches can achieve high accuracy on verifiable math problems\n",
    "- Single agent typically uses fewer tokens and tool calls\n",
    "- Multi-agent approach provides better modularity and specialization\n",
    "- Per-call `output` parameter provides flexible schema selection: `agent.run(task, output=MathSolution)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
